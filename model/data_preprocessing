# -*- coding: utf-8 -*-
"""Data_Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ObGZZRwzohKOVVu3WXDqtvmRX0UOfvo3
"""

# Data Cleaning and Preprocessing

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Set figure size
plt.rcParams["figure.figsize"] = (20, 10)

# Read the Excel file
df = pd.read_excel("C:\\Users\\USER\\Downloads\\customer_churn_large_dataset.xlsx")

# Check the unique columns
unique_columns = df.columns.unique()
print(unique_columns)

# Display the first few rows of the DataFrame
df.head()

print(df.describe())
print(df.dtypes)

# Check for missing values
print(df.isnull().sum())
df = df.dropna()
df.head()

# Checking for imbalance in the dataset
class_counts = df['Churn'].value_counts()

total_samples = len(df)
percent_churn_0 = (class_counts[0] / total_samples) * 100
percent_churn_1 = (class_counts[1] / total_samples) * 100

print("Class distribution:")
print(f"Churn=0: {class_counts[0]} samples, {percent_churn_0:.2f}%")
print(f"Churn=1: {class_counts[1]} samples, {percent_churn_1:.2f}%")
plt.figure(figsize=(8, 6))
plt.bar(['Churn=0', 'Churn=1'], [class_counts[0], class_counts[1]])
plt.xlabel('Churn Class')
plt.ylabel('Number of Samples')
plt.title('Class Distribution')
plt.text('Churn=0', class_counts[0], f'{percent_churn_0:.2f}%', ha='center', va='bottom')
plt.text('Churn=1', class_counts[1], f'{percent_churn_1:.2f}%', ha='center', va='bottom')

plt.show()

numerical_cols = ['Age', 'Subscription_Length_Months', 'Monthly_Bill', 'Total_Usage_GB']
for col in numerical_cols:
    sns.boxplot(x=df[col])
    plt.show()

#dropping unnecessary columns
if 'CustomerID' in df.columns and 'Name' in df.columns:
    df = df.drop(columns=['CustomerID', 'Name'])

# one-hot encoding
if 'Gender' in df.columns:
    df = pd.get_dummies(df, columns=['Gender'], prefix=['Is'])

if 'Location' in df.columns:
    df = pd.get_dummies(df, columns=['Location'], prefix=['Location'])

print(df.head())

# Check if Churn column exists
if 'Churn' in df.columns:
    # Split the data into features and target variable
    X = df.drop(columns=['Churn'])
    y = df['Churn']

    # Train-Test-split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

df.to_csv('processed_data.csv', index=False)
